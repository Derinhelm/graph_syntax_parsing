{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Derinhelm/graph_syntax_parsing/blob/main/Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOZsD_SFlTBL"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vnKegDLOlSYC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pvspeC3VaZil",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "3lOEPDrgK5V-"
      },
      "outputs": [],
      "source": [
        "! pip install jax\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdx-JRvRHc1g"
      },
      "source": [
        "# Loading scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viFqPlQ8HcCT",
        "outputId": "a6c398e3-fcad-4d58-be5c-cc2dfd3a945a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'graph_syntax_parsing'...\n",
            "remote: Enumerating objects: 366, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 366 (delta 56), reused 89 (delta 48), pack-reused 262\u001b[K\n",
            "Receiving objects: 100% (366/366), 97.12 MiB | 28.60 MiB/s, done.\n",
            "Resolving deltas: 100% (210/210), done.\n",
            "Updating files: 100% (23/23), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Derinhelm/graph_syntax_parsing.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01G-nT6mB7H"
      },
      "source": [
        "# uuparser/parser.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vv92PsZIIn8B",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/graph_syntax_parsing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tvCvxbrEH6MD",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from graph_syntax_parsing.utils import set_seeds, read_conll, ConllEntry, get_irels\n",
        "from graph_syntax_parsing.project_logging import logging\n",
        "from graph_syntax_parsing.project_parser import Parser\n",
        "from graph_syntax_parsing.run import run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "HPp79TnLK5WC",
        "outputId": "be640e68-e10f-4737-9070-6c6cf9d6f066"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/lib/__init__.py:24\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mjaxlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjaxlib\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jaxlib'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m set_seeds, read_conll, ConllEntry, get_irels\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mproject_logging\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mproject_parser\u001b[39;00m \u001b[39mimport\u001b[39;00m Parser\n",
            "File \u001b[0;32m/media/derin/DATA/Aspirantura/my_parser/graph_syntax_parsing/project_parser.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfiguration\u001b[39;00m \u001b[39mimport\u001b[39;00m Configuration\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m SWAP\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39moracle\u001b[39;00m \u001b[39mimport\u001b[39;00m Oracle\n",
            "File \u001b[0;32m/media/derin/DATA/Aspirantura/my_parser/graph_syntax_parsing/configuration.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m HeteroData\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m int32\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m LEFT_ARC, RIGHT_ARC, SHIFT, SWAP\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/__init__.py:35\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdel\u001b[39;00m _cloud_tpu_init\n\u001b[1;32m     32\u001b[0m \u001b[39m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m \u001b[39mimport\u001b[39;00m config \u001b[39mas\u001b[39;00m _config_module\n\u001b[1;32m     36\u001b[0m \u001b[39mdel\u001b[39;00m _config_module\n\u001b[1;32m     38\u001b[0m \u001b[39m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/config.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# TODO(phawkins): fix users of this alias and delete this file.\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m config  \u001b[39m# noqa: F401\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/config.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreading\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, List, Callable, Hashable, NamedTuple, Iterator, Optional\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m \u001b[39mimport\u001b[39;00m lib\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m jax_jit\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m transfer_guard_lib\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/jax/_src/lib/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mjaxlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjaxlib\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m---> 26\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mjax requires jaxlib to be installed. See \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     28\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mhttps://github.com/google/jax#installation for installation instructions.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     29\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m jax\u001b[39m.\u001b[39mversion\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m _minimum_jaxlib_version \u001b[39mas\u001b[39;00m _minimum_jaxlib_version_str\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions."
          ]
        }
      ],
      "source": [
        "from utils import set_seeds, read_conll\n",
        "from project_logging import logging\n",
        "from run import run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piyEERqI0aM2"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TRsWauYAsgXt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z6WsiWLHK4ae",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "real_dataset = False\n",
        "colab_using = True\n",
        "embed_pickle_using = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NXLJlVWzHu90",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "if real_dataset:\n",
        "  train_a_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-train-a.conllu'\n",
        "  train_b_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-train-b.conllu'\n",
        "  train_c_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-train-c.conllu'\n",
        "\n",
        "  val_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-dev.conllu'\n",
        "  test_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-test.conllu'\n",
        "  if colab_using:\n",
        "    for p in [train_a_dir, train_b_dir, train_c_dir, val_dir, test_dir]:\n",
        "      p = \"/content/graph_syntax_parsing/\" + p\n",
        "\n",
        "  train_a, train_words_a = read_conll(train_a_dir)\n",
        "  train_b, train_words_b = read_conll(train_b_dir)\n",
        "  train_c, train_words_c = read_conll(train_c_dir)\n",
        "  train = train_a + train_b + train_c\n",
        "else:\n",
        "  train_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-train.conllu'\n",
        "  val_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-dev.conllu'\n",
        "  test_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-test.conllu'\n",
        "  if colab_using:\n",
        "    for p in [train_dir, val_dir, test_dir]:\n",
        "      p = \"/content/graph_syntax_parsing/\" + p\n",
        "  train, train_words = read_conll(train_dir)\n",
        "val, val_words = read_conll(val_dir)\n",
        "test, test_words = read_conll(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Utx9YkrjMX2f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "if not embed_pickle_using:\n",
        "  if real_dataset:\n",
        "    all_words = train_words_a | train_words_b | train_words_c | val_words | test_words\n",
        "  else:\n",
        "    all_words = train_words | val_words | test_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5J4o7_QiH6JH",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "options = {}\n",
        "options[\"hidden_dims\"] = 100 # MLP hidden layer dimensions\n",
        "options[\"learning_rate\"] = 0.001 # Learning rate for neural network optimizer\n",
        "\n",
        "options[\"dynamic_oracle\"] = True # Use the static oracle instead of the dynamic oracle\n",
        "\n",
        "options[\"epochs\"] = 10 # Number of epochs\n",
        "options[\"first_epoch\"] = 1\n",
        "\n",
        "# really important to do this before anything else to make experiments reproducible\n",
        "set_seeds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0fDj1MJpJBV3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertModel\n",
        "def get_embed(tokenizer, model, word): # TODO: переписать или убрать!\n",
        "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_states = outputs.last_hidden_state[0][0]\n",
        "    return last_hidden_states.detach().cpu()\n",
        "\n",
        "def create_embeds(embed_pickle=None):\n",
        "    if embed_pickle is None:\n",
        "        embeds = {}\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        logging.debug('Creating embeddings')\n",
        "        ts = time.time()\n",
        "\n",
        "        for word in all_words:\n",
        "            embeds[word] = get_embed(tokenizer, model, word)\n",
        "        logging.debug(f'{len(embeds)} embeddings were created')\n",
        "        te = time.time()\n",
        "        logging.info(f'Time of embedding creation: {te-ts:.2g}s')\n",
        "    else:\n",
        "        ts = time.time()\n",
        "        embeds = []\n",
        "        with open(embed_pickle, 'rb') as f:\n",
        "            embeds = pickle.load(f)\n",
        "        te = time.time()\n",
        "        logging.info(f'Time of embedding downloading: {te-ts:.2g}s')\n",
        "    return embeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LUSU6RwuIaAM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pickle\n",
        "if embed_pickle_using:\n",
        "  if real_dataset:\n",
        "    embeds = create_embeds(\"/content/graph_syntax_parsing/UD_Russian-SynTagRus/embeds.pickle\")\n",
        "  else:\n",
        "    embeds = create_embeds(\"/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/embeds.pickle\")\n",
        "else:\n",
        "  embeds = create_embeds()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCrdg03Vvrid",
        "outputId": "d02655ef-735a-4aa3-88ed-4cd6e7dd0a2b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "516"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(embeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4dk0TJSIASC",
        "outputId": "3fd88185-35fa-4d5b-bc00-20ffed315823",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IbKLEjhM2L9",
        "outputId": "aac1d464-d6e8-4f46-8a86-8dcd38333833",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "jaxlib.mlir._mlir_libs - DEBUG - Initializing MLIR with module: _site_initialize_0\n",
            "jaxlib.mlir._mlir_libs - DEBUG - Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\n",
            "jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.\n",
            "root - INFO - Reading /content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-train.conllu\n",
            "root - DEBUG - 5 sentences read\n",
            "root - INFO - Time: 0.0005s\n",
            "root - INFO - Reading /content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-dev.conllu\n",
            "root - DEBUG - 25 sentences read\n",
            "root - INFO - Time: 0.013s\n",
            "root - INFO - Reading /content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-test.conllu\n",
            "root - DEBUG - 27 sentences read\n",
            "root - INFO - Time: 0.0059s\n",
            "root - DEBUG - Using default Python seed\n",
            "root - INFO - Time of embedding downloading: 0.068s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(Path('/content/app.log').read_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "oNypIrvK-8yt",
        "outputId": "06058dc4-df93-431d-fd18-64a8eeba4bbe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3a4ee747aa9b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/graph_syntax_parsing/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(traindata, valdata, testdata, embeds, options)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Starting epoch {epoch} (training)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Finished epoch {epoch} (training)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graph_syntax_parsing/project_parser.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, trainData)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graph_syntax_parsing/project_parser.py\u001b[0m in \u001b[0;36mtrain_sentence\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mirels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graph_syntax_parsing/configuration.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentence, irels)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# ensures we are working with a clean copy of sentence and allows memory to be recycled each time round the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConllEntry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "run(train, val, test, embeds, options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nowty9TabFph",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "logging.info(f'evaluate_time: {evaluate_time:.2g}s, transform_time:{transform_time:.2g}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqEC-RRSWbUR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"app.log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB8WaJlLkGDT"
      },
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0jIrXhiBLRM"
      },
      "source": [
        "TODO:\n",
        "В sentence последний элемент -\n",
        "\n",
        "{'id': 0,\n",
        " 'form': '*root*',\n",
        " 'char_rep': '*root*',\n",
        " 'norm': '*root*',\n",
        " 'cpos': 'ROOT-CPOS',\n",
        " 'pos': 'ROOT-POS',\n",
        " 'parent_id': -1,\n",
        " 'relation': 'rroot',\n",
        " 'lemma': '*root*',\n",
        " 'feats': '_',\n",
        " 'deps': '_',\n",
        " 'misc': '_',\n",
        " 'pred_parent_id': None,\n",
        " 'pred_relation': None,\n",
        " 'treebank_id': None,\n",
        " 'proxy_tbank': None,\n",
        " 'pred_pos': None,\n",
        " 'pred_cpos': None,\n",
        " 'projective_order': 0,\n",
        " 'rdeps': [8],\n",
        " 'children': [],\n",
        " 'scores': None,\n",
        " 'parent': None,\n",
        " 'vecs': None}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1apfPV9kHRa"
      },
      "source": [
        "В какую сторону стек в коде сейчас ?\n",
        "Используют stack[-1], stack[-2].\n",
        "Стек или очередь ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su65X20Amqjk"
      },
      "source": [
        "Разобраться, какие метрики считают при обучении (на train)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}