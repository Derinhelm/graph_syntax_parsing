{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Derinhelm/graph_syntax_parsing/blob/main/Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOZsD_SFlTBL"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vnKegDLOlSYC"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pvspeC3VaZil"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading scripts"
      ],
      "metadata": {
        "id": "rdx-JRvRHc1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Derinhelm/graph_syntax_parsing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viFqPlQ8HcCT",
        "outputId": "3127a505-15dc-4136-8c07-4162baf67d28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'graph_syntax_parsing'...\n",
            "remote: Enumerating objects: 358, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 358 (delta 51), reused 84 (delta 45), pack-reused 262\u001b[K\n",
            "Receiving objects: 100% (358/358), 97.11 MiB | 22.83 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n",
            "Updating files: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OShpLwXMo1bx"
      },
      "source": [
        "# Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yL_DsoclYTr"
      },
      "source": [
        "#uuparser/utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jMvUaVzlnEt"
      },
      "source": [
        "# uuparser/multilayer_perceptron.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bqNBhJ3ilnPT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHwx8pKPlyQb"
      },
      "source": [
        "# uuparser/arc_hybrid.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeMXyAEjgagf"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weEVVEh23Dc5"
      },
      "source": [
        "## Oracle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxiPi0Trgh1_"
      },
      "source": [
        "## Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01G-nT6mB7H"
      },
      "source": [
        "# uuparser/parser.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/graph_syntax_parsing')"
      ],
      "metadata": {
        "id": "vv92PsZIIn8B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from graph_syntax_parsing.utils import set_seeds, read_conll, ConllEntry, get_irels\n",
        "from graph_syntax_parsing.project_logging import logging\n",
        "from graph_syntax_parsing.project_parser import Parser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvCvxbrEH6MD",
        "outputId": "cf8fc6f1-84dd-4e04-9f15-d019e1f32790"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "\n",
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "484-h9BXlnU7"
      },
      "outputs": [],
      "source": [
        "import pickle, os, time, sys, copy, itertools, re, random\n",
        "\n",
        "from shutil import copyfile\n",
        "\n",
        "def evaluate_uas(sentence_descr):\n",
        "    #sentence_descr is a list, in which elements 0, 1, 2 are auxiliary\n",
        "    right_parent_tokens = 0\n",
        "    for token in sentence_descr[3:]:\n",
        "        if isinstance(token, ConllEntry): # TODO: изучить случаи, когда не ConllEntry - ошибка считывания?\n",
        "          if token.pred_parent_id == token.parent_id:\n",
        "              right_parent_tokens += 1\n",
        "        #print(\"pred_parent:\", token.pred_parent_id, \"real_parent:\", token.parent_id)\n",
        "    uas = right_parent_tokens / (len(sentence_descr) - 3)\n",
        "    return uas\n",
        "\n",
        "def evaluate_uas_epoche(sentence_list):\n",
        "    summ_uas = 0\n",
        "    for sent in sentence_list:\n",
        "        summ_uas += evaluate_uas(sent)\n",
        "    return summ_uas / len(sentence_list)\n",
        "\n",
        "p = None\n",
        "\n",
        "def run(traindata, valdata, testdata, embeds, options):\n",
        "\n",
        "    irels = get_irels(traindata)\n",
        "    logging.debug('Initializing the model')\n",
        "    parser = Parser(options, irels, embeds)\n",
        "    global p\n",
        "    p = parser\n",
        "\n",
        "    dev_best = [options[\"epochs\"],-1.0] # best epoch, best score\n",
        "\n",
        "    for epoch in range(options[\"first_epoch\"], options[\"epochs\"] + 1):\n",
        "        # Training\n",
        "        logging.info(f'Starting epoch {epoch} (training)')\n",
        "        parser.Train(traindata)\n",
        "        logging.info(f'Finished epoch {epoch} (training)')\n",
        "\n",
        "        parser.Save(epoch)\n",
        "\n",
        "        logging.info(f\"Predicting on dev data\")\n",
        "        dev_pred = list(parser.Predict(valdata))\n",
        "        mean_dev_score = evaluate_uas_epoche(dev_pred)\n",
        "        logging.info(f\"Dev score {mean_dev_score:.2f} at epoch {epoch:d}\")\n",
        "        print(f\"Dev score {mean_dev_score:.2f} at epoch {epoch:d}\")\n",
        "\n",
        "        if mean_dev_score > dev_best[1]:\n",
        "            dev_best = [epoch,mean_dev_score] # update best dev score\n",
        "\n",
        "    logging.info(f\"Loading best model from epoche{dev_best[0]:d}\")\n",
        "    # Loading best_models to parser.labeled_GNN and parser.unlabeled_GNN\n",
        "    parser.Load(epoch)\n",
        "\n",
        "    logging.info(f\"Predicting on test data\")\n",
        "\n",
        "    test_pred = list(parser.Predict(testdata))\n",
        "    mean_test_score = evaluate_uas_epoche(test_pred)\n",
        "\n",
        "    logging.info(f\"On test obtained UAS score of {mean_test_score:.2f}\")\n",
        "    print(f\"On test obtained UAS score of {mean_test_score:.2f}\")\n",
        "\n",
        "\n",
        "    logging.debug('Finished predicting')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "piyEERqI0aM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/models\""
      ],
      "metadata": {
        "id": "TRsWauYAsgXt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_dataset = False\n",
        "colab_using = True\n",
        "embed_pickle_using = True"
      ],
      "metadata": {
        "id": "z6WsiWLHK4ae"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if real_dataset:\n",
        "  train_a_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-train-a.conllu'\n",
        "  train_b_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-train-b.conllu'\n",
        "  train_c_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-train-c.conllu'\n",
        "\n",
        "  val_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-dev.conllu'\n",
        "  test_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus/ru_syntagrus-ud-test.conllu'\n",
        "  if colab_using:\n",
        "    for p in [train_a_dir, train_b_dir, train_c_dir, val_dir, test_dir]:\n",
        "      p = \"/content/graph_syntax_parsing/\" + p\n",
        "\n",
        "  train_a, train_words_a = read_conll(train_a_dir)\n",
        "  train_b, train_words_b = read_conll(train_b_dir)\n",
        "  train_c, train_words_c = read_conll(train_c_dir)\n",
        "  train = train_a + train_b + train_c\n",
        "else:\n",
        "  train_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-train.conllu'\n",
        "  val_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-dev.conllu'\n",
        "  test_dir = '/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-test.conllu'\n",
        "  if colab_using:\n",
        "    for p in [train_dir, val_dir, test_dir]:\n",
        "      p = \"/content/graph_syntax_parsing/\" + p\n",
        "  train, train_words = read_conll(train_dir)\n",
        "val, val_words = read_conll(val_dir)\n",
        "test, test_words = read_conll(test_dir)"
      ],
      "metadata": {
        "id": "NXLJlVWzHu90"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not embed_pickle_using:\n",
        "  if real_dataset:\n",
        "    all_words = train_words_a | train_words_b | train_words_c | val_words | test_words\n",
        "  else:\n",
        "    all_words = train_words | val_words | test_words\n"
      ],
      "metadata": {
        "id": "Utx9YkrjMX2f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5J4o7_QiH6JH"
      },
      "outputs": [],
      "source": [
        "options = {}\n",
        "options[\"hidden_dims\"] = 100 # MLP hidden layer dimensions\n",
        "options[\"learning_rate\"] = 0.001 # Learning rate for neural network optimizer\n",
        "\n",
        "options[\"dynamic_oracle\"] = True # Use the static oracle instead of the dynamic oracle\n",
        "\n",
        "options[\"epochs\"] = 10 # Number of epochs\n",
        "options[\"first_epoch\"] = 1\n",
        "\n",
        "# really important to do this before anything else to make experiments reproducible\n",
        "set_seeds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0fDj1MJpJBV3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertModel\n",
        "def get_embed(tokenizer, model, word): # TODO: переписать или убрать!\n",
        "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_states = outputs.last_hidden_state[0][0]\n",
        "    return last_hidden_states.detach().cpu()\n",
        "\n",
        "def create_embeds(embed_pickle=None):\n",
        "    if embed_pickle is None:\n",
        "        embeds = {}\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        logging.debug('Creating embeddings')\n",
        "        ts = time.time()\n",
        "\n",
        "        for word in all_words:\n",
        "            embeds[word] = get_embed(tokenizer, model, word)\n",
        "        logging.debug(f'{len(embeds)} embeddings were created')\n",
        "        te = time.time()\n",
        "        logging.info(f'Time of embedding creation: {te-ts:.2g}s')\n",
        "    else:\n",
        "        ts = time.time()\n",
        "        embeds = []\n",
        "        with open(embed_pickle, 'rb') as f:\n",
        "            embeds = pickle.load(f)\n",
        "        te = time.time()\n",
        "        logging.info(f'Time of embedding downloading: {te-ts:.2g}s')\n",
        "    return embeds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pickle\n",
        "if embed_pickle_using:\n",
        "  if real_dataset:\n",
        "    embeds = create_embeds(\"/content/graph_syntax_parsing/UD_Russian-SynTagRus/embeds.pickle\")\n",
        "  else:\n",
        "    embeds = create_embeds(\"/content/graph_syntax_parsing/UD_Russian-SynTagRus-small/embeds.pickle\")\n",
        "else:\n",
        "  embeds = create_embeds()\n"
      ],
      "metadata": {
        "id": "LUSU6RwuIaAM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCrdg03Vvrid",
        "outputId": "ec2f0207-c5b4-4e4e-d41e-7024fb7f513f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "516"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4dk0TJSIASC",
        "outputId": "5f7a5b8e-615e-46fb-a2ed-a47b6b7cae4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IbKLEjhM2L9",
        "outputId": "f7f73a43-b94b-441c-a7d3-433cc348a954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "jaxlib.mlir._mlir_libs - DEBUG - Initializing MLIR with module: _site_initialize_0\n",
            "jaxlib.mlir._mlir_libs - DEBUG - Registering dialects from initializer <module 'jaxlib.mlir._mlir_libs._site_initialize_0' from '/usr/local/lib/python3.10/dist-packages/jaxlib/mlir/_mlir_libs/_site_initialize_0.so'>\n",
            "jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.\n",
            "root - INFO - Reading /content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-train.conllu\n",
            "root - DEBUG - 5 sentences read\n",
            "root - INFO - Time: 0.0012s\n",
            "root - INFO - Reading /content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-dev.conllu\n",
            "root - DEBUG - 25 sentences read\n",
            "root - INFO - Time: 0.011s\n",
            "root - INFO - Reading /content/graph_syntax_parsing/UD_Russian-SynTagRus-small/ru_syntagrus-ud-test.conllu\n",
            "root - DEBUG - 27 sentences read\n",
            "root - INFO - Time: 0.006s\n",
            "root - DEBUG - Using default Python seed\n",
            "root - INFO - Time of embedding downloading: 0.11s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(Path('/content/app.log').read_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "oNypIrvK-8yt",
        "outputId": "d13e0f8f-1c07-4be4-985e-35e89ce5af10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3a4ee747aa9b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-7cfc74d1489a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(traindata, valdata, testdata, embeds, options)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Starting epoch {epoch} (training)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Finished epoch {epoch} (training)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graph_syntax_parsing/project_parser.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, trainData)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graph_syntax_parsing/project_parser.py\u001b[0m in \u001b[0;36mtrain_sentence\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mirels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graph_syntax_parsing/configuration.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentence, irels)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# ensures we are working with a clean copy of sentence and allows memory to be recycled each time round the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConllEntry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "run(train, val, test, embeds, options)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(f'evaluate_time: {evaluate_time:.2g}s, transform_time:{transform_time:.2g}')"
      ],
      "metadata": {
        "id": "Nowty9TabFph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"app.log\")"
      ],
      "metadata": {
        "id": "EqEC-RRSWbUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB8WaJlLkGDT"
      },
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0jIrXhiBLRM"
      },
      "source": [
        "TODO:\n",
        "В sentence последний элемент -\n",
        "\n",
        "{'id': 0,\n",
        " 'form': '*root*',\n",
        " 'char_rep': '*root*',\n",
        " 'norm': '*root*',\n",
        " 'cpos': 'ROOT-CPOS',\n",
        " 'pos': 'ROOT-POS',\n",
        " 'parent_id': -1,\n",
        " 'relation': 'rroot',\n",
        " 'lemma': '*root*',\n",
        " 'feats': '_',\n",
        " 'deps': '_',\n",
        " 'misc': '_',\n",
        " 'pred_parent_id': None,\n",
        " 'pred_relation': None,\n",
        " 'treebank_id': None,\n",
        " 'proxy_tbank': None,\n",
        " 'pred_pos': None,\n",
        " 'pred_cpos': None,\n",
        " 'projective_order': 0,\n",
        " 'rdeps': [8],\n",
        " 'children': [],\n",
        " 'scores': None,\n",
        " 'parent': None,\n",
        " 'vecs': None}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1apfPV9kHRa"
      },
      "source": [
        "В какую сторону стек в коде сейчас ?\n",
        "Используют stack[-1], stack[-2].\n",
        "Стек или очередь ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su65X20Amqjk"
      },
      "source": [
        "Разобраться, какие метрики считают при обучении (на train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}