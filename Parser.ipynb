{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Derinhelm/graph_syntax_parsing/blob/main/Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOZsD_SFlTBL"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnKegDLOlSYC",
        "outputId": "9880f26c-0b4a-47d4-8ea4-3cb6d021fae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pvspeC3VaZil"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OShpLwXMo1bx"
      },
      "source": [
        "# Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "kTho6ijao0_w"
      },
      "outputs": [],
      "source": [
        "\n",
        "import logging\n",
        "logger = logging.getLogger('my_logger')\n",
        "\n",
        "# Remove all handlers associated with the root logger object.\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename='app.log', # write to this file\n",
        "    filemode='a', # open in append mode\n",
        "    format='%(name)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "logging.getLogger(\"urllib3.connectionpool\").disabled = True\n",
        "logging.getLogger(\"filelock\").disabled = True\n",
        "\n",
        "logging.warning('This will get logged to a file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "h1IM4l2No4-U"
      },
      "outputs": [],
      "source": [
        "logging.warning('New warning')\n",
        "logging.debug('New debug')\n",
        "logging.info('New info')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "-V3mnSrwo6_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7fc799-68bb-4acf-fade-ef6419ad48bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "print(Path('/content/app.log').read_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yL_DsoclYTr"
      },
      "source": [
        "#uuparser/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Uhc-Hm49lfaf"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "import os,time\n",
        "from operator import itemgetter\n",
        "import random\n",
        "import json\n",
        "import pathlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class ConllEntry:\n",
        "    def __init__(self, id, form, lemma, pos, cpos, feats=None, parent_id=None, relation=None,\n",
        "        deps=None, misc=None):\n",
        "\n",
        "        self.id = id\n",
        "        self.form = form\n",
        "        self.cpos = cpos\n",
        "        self.pos = pos\n",
        "        self.parent_id = parent_id\n",
        "        self.relation = relation\n",
        "\n",
        "        self.lemma = lemma\n",
        "        self.feats = feats\n",
        "        self.deps = deps\n",
        "        self.misc = misc\n",
        "\n",
        "        self.pred_parent_id = None\n",
        "        self.pred_relation = None\n",
        "\n",
        "        self.pred_pos = None\n",
        "        self.pred_cpos = None\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        '''values = [str(self.id), self.form, self.lemma, \\\n",
        "                  self.pred_cpos if self.pred_cpos else self.cpos,\\\n",
        "                  self.pred_pos if self.pred_pos else self.pos,\\\n",
        "                  self.feats, str(self.pred_parent_id) if self.pred_parent_id \\\n",
        "                  is not None else str(self.parent_id), self.pred_relation if\\\n",
        "                  self.pred_relation is not None else self.relation, \\\n",
        "                  self.deps, self.misc]\n",
        "        return '\\t'.join(['_' if v is None else v for v in values])'''\n",
        "        return self.form + \" \" + str(self.id)\n",
        "\n",
        "class ParseForest:\n",
        "    def __init__(self, sentence):\n",
        "        self.roots = list(sentence)\n",
        "\n",
        "        for root in self.roots:\n",
        "            root.children = []\n",
        "            root.scores = None\n",
        "            root.parent = None\n",
        "            root.pred_parent_id = None\n",
        "            root.pred_relation = None\n",
        "            root.vecs = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.roots)\n",
        "\n",
        "\n",
        "    def Attach(self, parent_index, child_index):\n",
        "        parent = self.roots[parent_index]\n",
        "        child = self.roots[child_index]\n",
        "\n",
        "        child.pred_parent_id = parent.id\n",
        "        del self.roots[child_index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \" \".join(map(str, self.roots))\n",
        "\n",
        "\n",
        "def isProj(sentence):\n",
        "    forest = ParseForest(sentence)\n",
        "    unassigned = {entry.id: sum([1 for pentry in sentence if pentry.parent_id == entry.id]) for entry in sentence}\n",
        "\n",
        "    for _ in xrange(len(sentence)):\n",
        "        for i in xrange(len(forest.roots) - 1):\n",
        "            if forest.roots[i].parent_id == forest.roots[i+1].id and unassigned[forest.roots[i].id] == 0:\n",
        "                unassigned[forest.roots[i+1].id]-=1\n",
        "                forest.Attach(i+1, i)\n",
        "                break\n",
        "            if forest.roots[i+1].parent_id == forest.roots[i].id and unassigned[forest.roots[i+1].id] == 0:\n",
        "                unassigned[forest.roots[i].id]-=1\n",
        "                forest.Attach(i, i+1)\n",
        "                break\n",
        "\n",
        "    return len(forest.roots) == 1\n",
        "\n",
        "\n",
        "def get_irels(data):\n",
        "    \"\"\"\n",
        "    Collect frequencies of words, cpos, pos and deprels + languages.\n",
        "    \"\"\"\n",
        "\n",
        "    # could use sets directly rather than counters for most of these,\n",
        "    # but having the counts might be useful in the future or possibly for debugging etc\n",
        "    relCount = Counter()\n",
        "\n",
        "    for sentence in data:\n",
        "        for node in sentence:\n",
        "            if isinstance(node, ConllEntry):\n",
        "                relCount.update([node.relation])\n",
        "\n",
        "    return list(relCount.keys())\n",
        "\n",
        "\n",
        "def generate_root_token():\n",
        "    return ConllEntry(0, '*root*', '*root*', 'ROOT-POS', 'ROOT-CPOS', '_', -1,\n",
        "        'rroot', '_', '_')\n",
        "\n",
        "\n",
        "def read_conll(filename, drop_nproj=False, train=True):\n",
        "    fh = open(filename,'r',encoding='utf-8')\n",
        "    logging.info(f\"Reading {filename}\")\n",
        "    ts = time.time()\n",
        "    dropped = 0\n",
        "    sents_read = 0\n",
        "    sentences = []\n",
        "    tokens = [generate_root_token()]\n",
        "    words = [] # all words from the dataset\n",
        "    for line in fh:\n",
        "        tok = line.strip().split('\\t')\n",
        "        if not tok or line.strip() == '': # empty line, add sentence to list or yield\n",
        "            if len(tokens) > 1:\n",
        "                sents_read += 1\n",
        "                conll_tokens = [t for t in tokens if isinstance(t,ConllEntry)]\n",
        "                if not drop_nproj or isProj(conll_tokens): # keep going if it's projective or we're not dropping non-projective sents\n",
        "                    if train:\n",
        "                        inorder_tokens = inorder(conll_tokens)\n",
        "                        for i,t in enumerate(inorder_tokens):\n",
        "                            t.projective_order = i\n",
        "                        for tok in conll_tokens:\n",
        "                            tok.rdeps = [i.id for i in conll_tokens if i.parent_id == tok.id]\n",
        "                            if tok.id != 0:\n",
        "                                tok.parent_entry = [i for i in conll_tokens if i.id == tok.parent_id][0]\n",
        "                    sentences.append(tokens)\n",
        "                else:\n",
        "                    logging.debug('Non-projective sentence dropped')\n",
        "                    dropped += 1\n",
        "            tokens = [generate_root_token()]\n",
        "        else:\n",
        "            if line[0] == '#' or '-' in tok[0] or '.' in tok[0]: # a comment line, add to tokens as is\n",
        "                tokens.append(line.strip())\n",
        "            else: # an actual ConllEntry, add to tokens\n",
        "                if tok[2] == \"_\":\n",
        "                    tok[2] = tok[1].lower()\n",
        "                words.append(tok[2])\n",
        "                token = ConllEntry(int(tok[0]), tok[1], tok[2], tok[4], tok[3], tok[5], int(tok[6]) if tok[6] != '_' else -1, tok[7], tok[8], tok[9])\n",
        "\n",
        "                tokens.append(token)\n",
        "\n",
        "# deal with case where there are still tokens, that aren`t in sentences list\n",
        "# e.g. when there is no newline at end of file\n",
        "    if len(tokens) > 1:\n",
        "        sentences.append(tokens)\n",
        "\n",
        "    logging.debug(f'{sents_read} sentences read')\n",
        "\n",
        "    te = time.time()\n",
        "    logging.info(f'Time: {te-ts:.2g}s')\n",
        "    return sentences, words\n",
        "\n",
        "\n",
        "def write_conll(fn, conll_gen):\n",
        "    logging.info(f\"Writing to {fn}\")\n",
        "    sents = 0\n",
        "    with open(fn, 'w', encoding='utf-8') as fh:\n",
        "        for sentence in conll_gen:\n",
        "            sents += 1\n",
        "            for entry in sentence[1:]:\n",
        "                fh.write(str(entry) + '\\n')\n",
        "            fh.write('\\n')\n",
        "        logging.debug(f\"Wrote {sents} sentences\")\n",
        "\n",
        "\n",
        "numberRegex = re.compile(\"[0-9]+|[0-9]+\\\\.[0-9]+|[0-9]+[0-9,]+\");\n",
        "def normalize(word):\n",
        "    return 'NUM' if numberRegex.match(word) else word.lower()\n",
        "\n",
        "\n",
        "def inorder(sentence):\n",
        "    queue = [sentence[0]]\n",
        "    def inorder_helper(sentence,i):\n",
        "        results = []\n",
        "        left_children = [entry for entry in sentence[:i] if entry.parent_id == i]\n",
        "        for child in left_children:\n",
        "            results += inorder_helper(sentence,child.id)\n",
        "        results.append(sentence[i])\n",
        "\n",
        "        right_children = [entry for entry in sentence[i:] if entry.parent_id == i ]\n",
        "        for child in right_children:\n",
        "            results += inorder_helper(sentence,child.id)\n",
        "        return results\n",
        "    return inorder_helper(sentence,queue[0].id)\n",
        "\n",
        "\n",
        "def set_seeds():\n",
        "    python_seed = 1\n",
        "    logging.debug(\"Using default Python seed\")\n",
        "    random.seed(python_seed)\n",
        "\n",
        "\n",
        "def generate_seed():\n",
        "    return random.randint(0,10**9) # this range seems to work for Dynet and Python's random function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jMvUaVzlnEt"
      },
      "source": [
        "# uuparser/multilayer_perceptron.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "bqNBhJ3ilnPT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHwx8pKPlyQb"
      },
      "source": [
        "# uuparser/arc_hybrid.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "3zYFbQ4ivwnL"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from itertools import chain\n",
        "import time, random\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from collections import defaultdict\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import tqdm\n",
        "\n",
        "\n",
        "from jax.numpy import int32\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "b0hMZDgY7MC_"
      },
      "outputs": [],
      "source": [
        "def get_embed(tokenizer, model, word):\n",
        "\n",
        "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_states = outputs.last_hidden_state[0][0]\n",
        "    return last_hidden_states.detach().cpu()\n",
        "\n",
        "\n",
        "def get_embed_for_sentence(sentence):\n",
        "    word_embeds = torch.empty((len(sentence), 768))\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    for i in range(len(sentence)):\n",
        "        word_embeds[i] = get_embed(tokenizer, model, sentence[i].form)\n",
        "    return word_embeds\n",
        "\n",
        "def create_stack_edges(stack):\n",
        "    if len(stack) == 0:\n",
        "        return torch.stack((torch.tensor([], dtype=torch.int32), torch.tensor([], dtype=torch.int32)), dim=0)\n",
        "    stack_edges = []\n",
        "    if len(stack) == 1:\n",
        "        stack_edges.append((stack[0].id - 1, stack[0].id - 1)) # temporary solution\n",
        "    else:\n",
        "        for i in range(len(stack) - 1): # Represents every two consecutive stack nodes as an edge\n",
        "            stack_edges.append((stack[i].id - 1, stack[i + 1].id - 1))\n",
        "    stack_edges = tuple(zip(*stack_edges))\n",
        "    stack_edges = [torch.tensor(stack_edges[0]), torch.tensor(stack_edges[1])]\n",
        "    return torch.stack(stack_edges, dim=0)\n",
        "\n",
        "def create_buffer_edges(buffer):\n",
        "    if len(buffer) == 0 or len(buffer) == 1: # Last element is a technical root element.\n",
        "        return torch.stack((torch.tensor([], dtype=torch.int32), torch.tensor([], dtype=torch.int32)), dim=0)\n",
        "    buffer_edges = []\n",
        "    if len(buffer) == 2: # Last element is a technical root element.\n",
        "        buffer_edges.append((buffer[0].id - 1, buffer[0].id - 1)) # temporary solution\n",
        "    else:\n",
        "        for i in range(len(buffer) - 2): # Last element is a technical root element.\n",
        "        # Represents every two consecutive buffer nodes as an edge\n",
        "            buffer_edges.append((buffer[i].id - 1, buffer[i + 1].id - 1))\n",
        "    buffer_edges = tuple(zip(*buffer_edges))\n",
        "    buffer_edges = [torch.tensor(buffer_edges[0]), torch.tensor(buffer_edges[1])]\n",
        "    return torch.stack(buffer_edges, dim=0)\n",
        "\n",
        "def create_graph_edges(sentence):\n",
        "    graph_edges = []\n",
        "    for node in sentence:\n",
        "        if node.pred_parent_id is not None and node.pred_parent_id != 0 and node.pred_parent_id != -1:\n",
        "            graph_edges.append((node.pred_parent_id - 1, node.id - 1))\n",
        "    if len(graph_edges) == 0:\n",
        "        return torch.stack((torch.tensor([], dtype=torch.int32), torch.tensor([], dtype=torch.int32)), dim=0)\n",
        "    graph_edges = tuple(zip(*graph_edges))\n",
        "    graph_edges = [torch.tensor(graph_edges[0]), torch.tensor(graph_edges[1])]\n",
        "    return torch.stack(graph_edges, dim=0)\n",
        "\n",
        "def config_to_graph(sentence, stack, buffer):\n",
        "    word_embeds = get_embed_for_sentence(sentence)\n",
        "\n",
        "    data = HeteroData()\n",
        "    data['node']['x'] = word_embeds\n",
        "\n",
        "    data[('node', 'graph', 'node')].edge_index = create_graph_edges(sentence)\n",
        "    data[('node', 'stack', 'node')].edge_index = create_stack_edges(stack)\n",
        "    data[('node', 'buffer', 'node')].edge_index = create_buffer_edges(buffer)\n",
        "    return data\n",
        "\n",
        "class Configuration:\n",
        "    def __init__(self, sentence, irels):\n",
        "        self.sentence = deepcopy(sentence) # ensures we are working with a clean copy of sentence and allows memory to be recycled each time round the loop\n",
        "        self.sentence = [entry for entry in self.sentence if isinstance(entry, ConllEntry)]\n",
        "        self.sentence = self.sentence[1:] + [self.sentence[0]]\n",
        "        self.stack = ParseForest([])\n",
        "        self.buffer = ParseForest(self.sentence)\n",
        "        for root in self.sentence:\n",
        "            root.relation = root.relation if root.relation in irels else 'runk'\n",
        "\n",
        "    def get_stack(self):\n",
        "        return self.stack\n",
        "\n",
        "    def get_buffer(self):\n",
        "        return self.buffer\n",
        "\n",
        "    def get_sentence(self):\n",
        "        return self.sentence\n",
        "\n",
        "    def is_end(self):\n",
        "        return len(self.buffer) == 1 and len(self.stack) == 0\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"stack:\" + str(self.stack) + \"\\n\" + \"buffer:\" + str(self.buffer) + \"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "eQsABNd7lnST"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ArcHybridLSTM:\n",
        "    def __init__(self, options, out_irels_dims):\n",
        "\n",
        "        global LEFT_ARC, RIGHT_ARC, SHIFT, SWAP\n",
        "        LEFT_ARC, RIGHT_ARC, SHIFT, SWAP = 0,1,2,3\n",
        "\n",
        "        self.oracle = options[\"oracle\"]\n",
        "\n",
        "        self.hidden_dims = options[\"hidden_dims\"]\n",
        "        self.out_irels_dims = out_irels_dims\n",
        "\n",
        "        self.metadata = (['node'], [('node', 'graph', 'node'), ('node', 'stack', 'node'), ('node', 'buffer', 'node')])\n",
        "        self.unlabeled_GNN = GNN(hidden_channels=self.hidden_dims, out_channels=4)\n",
        "        self.unlabeled_GNN = to_hetero(self.unlabeled_GNN, self.metadata, aggr='sum')\n",
        "\n",
        "        self.labeled_GNN = GNN(hidden_channels=self.hidden_dims, out_channels=2*self.out_irels_dims+2)\n",
        "        self.labeled_GNN = to_hetero(self.labeled_GNN, self.metadata, aggr='sum')\n",
        "\n",
        "        self.unlabeled_optimizer = optim.Adam(self.unlabeled_GNN.parameters(), lr=options[\"learning_rate\"])\n",
        "        self.labeled_optimizer = optim.Adam(self.labeled_GNN.parameters(), lr=options[\"learning_rate\"])\n",
        "\n",
        "\n",
        "    def __evaluate(self, config, train, irels):\n",
        "        \"\"\"\n",
        "        ret = [left arc,\n",
        "               right arc\n",
        "               shift]\n",
        "\n",
        "        RET[i] = (rel, transition, score1, score2) for shift, l_arc and r_arc\n",
        "         shift = 2 (==> rel=None) ; l_arc = 0; r_acr = 1\n",
        "\n",
        "        ret[i][j][2] ~= ret[i][j][3] except the latter is a dynet\n",
        "        expression used in the loss, the first is used in rest of training\n",
        "        \"\"\"\n",
        "\n",
        "        stack = config.get_stack()\n",
        "        buf = config.get_buffer()\n",
        "        sentence = config.get_sentence()\n",
        "        graph = config_to_graph(sentence, stack.roots, buf.roots)\n",
        "        output = self.unlabeled_GNN(graph.x_dict, graph.edge_index_dict)\n",
        "        output = torch.sum(output['node'], dim=0)\n",
        "        routput = self.labeled_GNN(graph.x_dict, graph.edge_index_dict)\n",
        "        routput = torch.sum(routput['node'], dim=0)\n",
        "\n",
        "        #scores, unlabeled scores\n",
        "        scrs, uscrs = routput, output\n",
        "\n",
        "        #transition conditions\n",
        "        left_arc_conditions = len(stack) > 0\n",
        "        right_arc_conditions = len(stack) > 1\n",
        "        shift_conditions = buf.roots[0].id != 0\n",
        "        swap_conditions = len(stack) > 0 and stack.roots[-1].id < buf.roots[0].id\n",
        "\n",
        "        if not train:\n",
        "            #(avoiding the multiple roots problem: disallow left-arc from root\n",
        "            #if stack has more than one element\n",
        "            left_arc_conditions = left_arc_conditions and not (buf.roots[0].id == 0 and len(stack) > 1)\n",
        "\n",
        "        uscrs0, uscrs1, uscrs2, uscrs3 = uscrs[0], uscrs[1], uscrs[2], uscrs[3]\n",
        "\n",
        "        if train:\n",
        "            output0, output1, output2, output3 = output[0], output[1], output[2], output[3]\n",
        "\n",
        "\n",
        "            ret = [ [ (rel, LEFT_ARC, scrs[2 + j * 2] + uscrs2, routput[2 + j * 2 ] + output2) for j, rel in enumerate(irels) ] if left_arc_conditions else [],\n",
        "                   [ (rel, RIGHT_ARC, scrs[3 + j * 2] + uscrs3, routput[3 + j * 2 ] + output3) for j, rel in enumerate(irels) ] if right_arc_conditions else [],\n",
        "                   [ (None, SHIFT, scrs[0] + uscrs0, routput[0] + output0) ] if shift_conditions else [] ,\n",
        "                    [ (None, SWAP, scrs[1] + uscrs1, routput[1] + output1) ] if swap_conditions else [] ]\n",
        "        else:\n",
        "            s1,r1 = max(zip(scrs[2::2],irels))\n",
        "            s2,r2 = max(zip(scrs[3::2],irels))\n",
        "            s1 = s1 + uscrs2\n",
        "            s2 = s2 + uscrs3\n",
        "            ret = [ [ (r1, LEFT_ARC, s1) ] if left_arc_conditions else [],\n",
        "                   [ (r2, RIGHT_ARC, s2) ] if right_arc_conditions else [],\n",
        "                   [ (None, SHIFT, scrs[0] + uscrs0) ] if shift_conditions else [] ,\n",
        "                    [ (None, SWAP, scrs[1] + uscrs1) ] if swap_conditions else [] ]\n",
        "        return ret\n",
        "\n",
        "    def Load(self, epoch):\n",
        "        unlab_path = 'model_unlab' + '_' + str(epoch)\n",
        "        lab_path = 'model_lab' + '_' + str(epoch)\n",
        "\n",
        "        self.unlabeled_GNN = GNN(hidden_channels=self.hidden_dims, out_channels=4)\n",
        "        self.labeled_GNN = GNN(hidden_channels=self.hidden_dims, out_channels=2*self.out_irels_dims+2)\n",
        "\n",
        "        unlab_checkpoint = torch.load(unlab_path)\n",
        "        self.unlabeled_GNN.load_state_dict(unlab_checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "        self.unlabeled_GNN = to_hetero(self.unlabeled_GNN, self.metadata, aggr='sum')\n",
        "        self.labeled_GNN = to_hetero(self.labeled_GNN, self.metadata, aggr='sum')\n",
        "\n",
        "        lab_checkpoint = torch.load(lab_path)\n",
        "        self.labeled_GNN.load_state_dict(lab_checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "    def Save(self, epoch):\n",
        "        unlab_path = 'model_unlab' + '_' + str(epoch)\n",
        "        lab_path = 'model_lab' + '_' + str(epoch)\n",
        "        logging.info(f'Saving unlabeled model to {unlab_path}')\n",
        "        torch.save({'epoch': epoch, 'model_state_dict': self.unlabeled_GNN.state_dict()}, unlab_path)\n",
        "        logging.info(f'Saving labeled model to {lab_path}')\n",
        "        torch.save({'epoch': epoch, 'model_state_dict': self.labeled_GNN.state_dict()}, lab_path)\n",
        "\n",
        "    def apply_transition(self, best, config):\n",
        "        stack = config.get_stack()\n",
        "        buf = config.get_buffer()\n",
        "        if best[1] == SHIFT:\n",
        "            stack.roots.append(buf.roots[0])\n",
        "            del buf.roots[0]\n",
        "\n",
        "        elif best[1] == SWAP:\n",
        "            child = stack.roots.pop()\n",
        "            buf.roots.insert(1,child)\n",
        "\n",
        "        elif best[1] == LEFT_ARC:\n",
        "            child = stack.roots.pop()\n",
        "            parent = buf.roots[0]\n",
        "\n",
        "        elif best[1] == RIGHT_ARC:\n",
        "            child = stack.roots.pop()\n",
        "            parent = stack.roots[-1]\n",
        "\n",
        "        if best[1] == LEFT_ARC or best[1] == RIGHT_ARC:\n",
        "            #attach\n",
        "            child.pred_parent_id = parent.id\n",
        "            child.pred_relation = best[0]\n",
        "\n",
        "    def calculate_cost(self,scores,s0,s1,b,beta,stack_ids):\n",
        "        if len(scores[LEFT_ARC]) == 0:\n",
        "            left_cost = 1\n",
        "        else:\n",
        "            left_cost = len(s0[0].rdeps) + int(s0[0].parent_id != b[0].id and s0[0].id in s0[0].parent_entry.rdeps)\n",
        "\n",
        "\n",
        "        if len(scores[RIGHT_ARC]) == 0:\n",
        "            right_cost = 1\n",
        "        else:\n",
        "            right_cost = len(s0[0].rdeps) + int(s0[0].parent_id != s1[0].id and s0[0].id in s0[0].parent_entry.rdeps)\n",
        "\n",
        "\n",
        "        if len(scores[SHIFT]) == 0:\n",
        "            shift_cost = 1\n",
        "            shift_case = 0\n",
        "        elif len([item for item in beta if item.projective_order < b[0].projective_order and item.id > b[0].id ])> 0:\n",
        "            shift_cost = 0\n",
        "            shift_case = 1\n",
        "        else:\n",
        "            shift_cost = len([d for d in b[0].rdeps if d in stack_ids]) + int(len(s0)>0 and b[0].parent_id in stack_ids[:-1] and b[0].id in b[0].parent_entry.rdeps)\n",
        "            shift_case = 2\n",
        "\n",
        "\n",
        "        if len(scores[SWAP]) == 0 :\n",
        "            swap_cost = 1\n",
        "        elif s0[0].projective_order > b[0].projective_order:\n",
        "            swap_cost = 0\n",
        "            #disable all the others\n",
        "            left_cost = right_cost = shift_cost = 1\n",
        "        else:\n",
        "            swap_cost = 1\n",
        "\n",
        "        costs = (left_cost, right_cost, shift_cost, swap_cost,1)\n",
        "        return costs, shift_case\n",
        "\n",
        "\n",
        "    def oracle_updates(self,best,b,s0,stack_ids,shift_case):\n",
        "        if best[1] == SHIFT:\n",
        "            if shift_case == 2:\n",
        "                if b[0].parent_entry.id in stack_ids[:-1] and b[0].id in b[0].parent_entry.rdeps:\n",
        "                    b[0].parent_entry.rdeps.remove(b[0].id)\n",
        "                blocked_deps = [d for d in b[0].rdeps if d in stack_ids]\n",
        "                for d in blocked_deps:\n",
        "                    b[0].rdeps.remove(d)\n",
        "\n",
        "        elif best[1] == LEFT_ARC or best[1] == RIGHT_ARC:\n",
        "            s0[0].rdeps = []\n",
        "            if s0[0].id in s0[0].parent_entry.rdeps:\n",
        "                s0[0].parent_entry.rdeps.remove(s0[0].id)\n",
        "\n",
        "    def Predict(self, data, datasplit, options, irels):\n",
        "        reached_max_swap = 0\n",
        "\n",
        "        pbar = tqdm.tqdm(\n",
        "            data,\n",
        "            desc=\"Parsing\",\n",
        "            unit=\"sentences\",\n",
        "            mininterval=1.0,\n",
        "            leave=False,\n",
        "            disable=False,\n",
        "        )\n",
        "\n",
        "        for iSentence, osentence in enumerate(pbar,1):\n",
        "            config = Configuration(osentence, irels)\n",
        "            max_swap = 2*len(osentence)\n",
        "            reached_swap_for_i_sentence = False\n",
        "            iSwap = 0\n",
        "\n",
        "            while not config.is_end():\n",
        "                scores = self.__evaluate(config, False, irels)\n",
        "                best = max(chain(*(scores if iSwap < max_swap else scores[:3] )), key = itemgetter(2) )\n",
        "                if iSwap == max_swap and not reached_swap_for_i_sentence:\n",
        "                    reached_max_swap += 1\n",
        "                    reached_swap_for_i_sentence = True\n",
        "                    logging.debug(f\"reached max swap in {reached_max_swap:d} out of {iSentence:d} sentences\")\n",
        "                self.apply_transition(best, config)\n",
        "                if best[1] == SWAP:\n",
        "                    iSwap += 1\n",
        "\n",
        "            #keep in memory the information we need, not all the vectors\n",
        "            oconll_sentence = [entry for entry in osentence if isinstance(entry, ConllEntry)]\n",
        "            oconll_sentence = oconll_sentence[1:] + [oconll_sentence[0]]\n",
        "            conll_sentence = config.get_sentence()\n",
        "            for tok_o, tok in zip(oconll_sentence, conll_sentence):\n",
        "                tok_o.pred_relation = tok.pred_relation\n",
        "                tok_o.pred_parent_id = tok.pred_parent_id\n",
        "            yield osentence\n",
        "\n",
        "    def cost_computing(self, config, scores, info):\n",
        "        stack = config.get_stack()\n",
        "        buf = config.get_buffer()\n",
        "\n",
        "        stack_ids = [sitem.id for sitem in stack.roots]\n",
        "\n",
        "        s1 = [stack.roots[-2]] if len(stack) > 1 else []\n",
        "        s0 = [stack.roots[-1]] if len(stack) > 0 else []\n",
        "        b = [buf.roots[0]] if len(buf) > 0 else []\n",
        "        beta = buf.roots[1:] if len(buf) > 1 else []\n",
        "\n",
        "        costs, shift_case = self.calculate_cost(scores,s0,s1,b,beta,stack_ids)\n",
        "\n",
        "        bestValid = list(( s for s in chain(*scores) if costs[s[1]] == 0 and ( s[1] == SHIFT or s[1] == SWAP or  s[0] == s0[0].relation ) ))\n",
        "\n",
        "        bestValid = max(bestValid, key=itemgetter(2))\n",
        "        bestWrong = max(( s for s in chain(*scores) if costs[s[1]] != 0 or ( s[1] != SHIFT and s[1] != SWAP and s[0] != s0[0].relation ) ), key=itemgetter(2))\n",
        "        #force swap\n",
        "        if costs[SWAP]== 0:\n",
        "            best = bestValid\n",
        "        else:\n",
        "        #select a transition to follow\n",
        "        # + aggresive exploration\n",
        "        #1: might want to experiment with that parameter\n",
        "            if bestWrong[1] == SWAP:\n",
        "                best = bestValid\n",
        "            else:\n",
        "                best = bestValid if ( (not self.oracle) or (bestValid[2] - bestWrong[2] > 1.0) or (bestValid[2] > bestWrong[2] and random.random() > 0.1) ) else bestWrong\n",
        "\n",
        "        #updates for the dynamic oracle\n",
        "        if self.oracle: # TODO: проверить, что значит True/False\n",
        "            self.oracle_updates(best,b,s0,stack_ids,shift_case)\n",
        "\n",
        "        #labeled errors\n",
        "        if best[1] == LEFT_ARC or best[1] == RIGHT_ARC:\n",
        "            child = s0[0]\n",
        "            if (child.pred_parent_id != child.parent_id or child.pred_relation != child.relation):\n",
        "                info[\"lerrors\"] += 1\n",
        "                #attachment error\n",
        "                if child.pred_parent_id != child.parent_id:\n",
        "                    info[\"eerrors\"] += 1\n",
        "\n",
        "        if bestValid[2] < bestWrong[2] + 1.0:\n",
        "            loss = bestWrong[3] - bestValid[3]\n",
        "            info[\"mloss\"] += 1.0 + bestWrong[2] - bestValid[2]\n",
        "            info[\"eloss\"] += 1.0 + bestWrong[2] - bestValid[2]\n",
        "            info[\"errs\"].append(loss)\n",
        "\n",
        "        #??? when did this happen and why?\n",
        "        if best[1] == 0 or best[1] == 2:\n",
        "            info[\"etotal\"] += 1\n",
        "\n",
        "        return best, info\n",
        "\n",
        "    def train_sentence(self, sentence, info, irels):\n",
        "            config = Configuration(sentence, irels)\n",
        "\n",
        "            ninf = -float('inf')\n",
        "            while not config.is_end():\n",
        "                print(config)\n",
        "                scores = self.__evaluate(config, True, irels)\n",
        "                scores.append([(None, 4, ninf ,None)]) #to ensure that we have at least one wrong operation\n",
        "\n",
        "                best, info = self.cost_computing(config, scores, info)\n",
        "\n",
        "                self.apply_transition(best, config)\n",
        "\n",
        "            return info\n",
        "\n",
        "    def error_processing(self, info):\n",
        "        errs = info[\"errs\"]\n",
        "        self.labeled_optimizer.zero_grad()\n",
        "        self.unlabeled_optimizer.zero_grad()\n",
        "        eerrs = torch.sum(torch.tensor(errs, requires_grad=True))\n",
        "        eerrs.backward()\n",
        "        self.labeled_optimizer.step() # TODO Какой из оптимизаторов ???\n",
        "        self.unlabeled_optimizer.step()\n",
        "        info[\"errs\"] = []\n",
        "\n",
        "    def create_info(self):\n",
        "        info = {}\n",
        "        info[\"mloss\"], info[\"eloss\"], info[\"eerrors\"], info[\"lerrors\"], info[\"etotal\"]  = 0.0, 0.0, 0, 0, 0\n",
        "        info[\"errs\"] = []\n",
        "        info[\"iSentence\"] = -1\n",
        "        info[\"start\"] = time.time()\n",
        "        return info\n",
        "\n",
        "    def train_logging(self, info):\n",
        "        loss_message = (\n",
        "            f'Processing sentence number: {info[\"iSentence\"]}'\n",
        "            f' Loss: {info[\"eloss\"] / info[\"etotal\"]:.3f}'\n",
        "            f' Errors: {info[\"eerrors\"] / info[\"etotal\"]:.3f}'\n",
        "            f' Labeled Errors: {info[\"lerrors\"] / info[\"etotal\"]:.3f}'\n",
        "            f' Time: {time.time()-info[\"start\"]:.3f}s'\n",
        "        )\n",
        "        logging.debug(loss_message)\n",
        "        info[\"start\"] = time.time() # TODO: зачем этот параметр ?\n",
        "        info[\"eerrors\"], info[\"eloss\"], info[\"etotal\"], info[\"lerrors\"] = 0, 0.0, 0, 0 # TODO: Почему здесь зануляем?\n",
        "\n",
        "    def Train(self, trainData, options, irels):\n",
        "        random.shuffle(trainData) # in certain cases the data will already have been shuffled after being read from file or while creating dev data\n",
        "        logging.info(f\"Length of training data: {len(trainData)}\")\n",
        "\n",
        "        beg = time.time()\n",
        "        info = self.create_info()\n",
        "\n",
        "        pbar = tqdm.tqdm(\n",
        "            trainData, desc=\"Training\", unit=\"sentences\",\n",
        "            mininterval=1.0, leave=False, disable=False,\n",
        "        )\n",
        "\n",
        "        for iSentence, sentence in enumerate(pbar,1):\n",
        "            print(\"-----------------------------------------------\")\n",
        "            print(\"Sentence №\", iSentence, sentence[2])\n",
        "            info[\"iSentence\"] = iSentence\n",
        "            if iSentence % 100 == 0:\n",
        "                self.train_logging(info)\n",
        "\n",
        "            info = self.train_sentence(sentence, info, irels)\n",
        "\n",
        "            #footnote 8 in Eli's original paper\n",
        "            if len(info[\"errs\"]) > 50: # or True:\n",
        "                self.error_processing(info)\n",
        "\n",
        "        if len(info[\"errs\"]) > 0:\n",
        "            self.error_processing(info)\n",
        "\n",
        "        logging.info(f\"Loss: {info['mloss']/info['iSentence']}\")\n",
        "        logging.info(f\"Total Training Time: {time.time()-beg:.2g}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01G-nT6mB7H"
      },
      "source": [
        "# uuparser/parser.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "484-h9BXlnU7"
      },
      "outputs": [],
      "source": [
        "import pickle, os, time, sys, copy, itertools, re, random\n",
        "\n",
        "from shutil import copyfile\n",
        "\n",
        "def evaluate_uas(sentence_descr):\n",
        "    #sentence_descr is a list, in which elements 0, 1, 2 are auxiliary\n",
        "    right_parent_tokens = 0\n",
        "    for token in sentence_descr[3:]:\n",
        "        if isinstance(token, ConllEntry): # TODO: изучить случаи, когда не ConllEntry - ошибка считывания?\n",
        "          if token.pred_parent_id == token.parent_id:\n",
        "              right_parent_tokens += 1\n",
        "        #print(\"pred_parent:\", token.pred_parent_id, \"real_parent:\", token.parent_id)\n",
        "    uas = right_parent_tokens / (len(sentence_descr) - 3)\n",
        "    return uas\n",
        "\n",
        "def evaluate_uas_epoche(sentence_list):\n",
        "    summ_uas = 0\n",
        "    for sent in sentence_list:\n",
        "        summ_uas += evaluate_uas(sent)\n",
        "    return summ_uas / len(sentence_list)\n",
        "\n",
        "def run(traindata, valdata, testdata, options):\n",
        "\n",
        "    irels = get_irels(traindata)\n",
        "    out_irels_dims = len(irels)\n",
        "    logging.debug('Initializing the model')\n",
        "    parser = ArcHybridLSTM(options, out_irels_dims)\n",
        "\n",
        "    dev_best = [options[\"epochs\"],-1.0] # best epoch, best score\n",
        "\n",
        "    for epoch in range(options[\"first_epoch\"], options[\"epochs\"] + 1):\n",
        "        # Training\n",
        "        logging.info(f'Starting epoch {epoch} (training)')\n",
        "        parser.Train(traindata,options, irels)\n",
        "        logging.info(f'Finished epoch {epoch} (training)')\n",
        "\n",
        "        parser.Save(epoch)\n",
        "\n",
        "        logging.info(f\"Predicting on dev data\")\n",
        "        dev_pred = list(parser.Predict(valdata,\"dev\",options, irels))\n",
        "        mean_dev_score = evaluate_uas_epoche(dev_pred)\n",
        "        logging.info(f\"Dev score {mean_dev_score:.2f} at epoch {epoch:d}\")\n",
        "        print(f\"Dev score {mean_dev_score:.2f} at epoch {epoch:d}\")\n",
        "\n",
        "        if mean_dev_score > dev_best[1]:\n",
        "            dev_best = [epoch,mean_dev_score] # update best dev score\n",
        "\n",
        "    logging.info(f\"Loading best model from epoche{dev_best[0]:d}\")\n",
        "    # Loading best_models to parser.labeled_GNN and parser.unlabeled_GNN\n",
        "    parser.Load(epoch)\n",
        "\n",
        "    logging.info(f\"Predicting on test data\")\n",
        "\n",
        "    test_pred = list(parser.Predict(testdata,\"test\",options, irels))\n",
        "    mean_test_score = evaluate_uas_epoche(test_pred)\n",
        "\n",
        "    logging.info(f\"On test obtained UAS score of {mean_test_score:.2f}\")\n",
        "    print(f\"On test obtained UAS score of {mean_test_score:.2f}\")\n",
        "\n",
        "\n",
        "    logging.debug('Finished predicting')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options = {}\n",
        "options[\"hidden_dims\"] = 100 # MLP hidden layer dimensions\n",
        "options[\"learning_rate\"] = 0.001 # Learning rate for neural network optimizer\n",
        "\n",
        "options[\"oracle\"] = True # Use the static oracle instead of the dynamic oracle\n",
        "\n",
        "options[\"epochs\"] = 30 # Number of epochs\n",
        "options[\"first_epoch\"] = 1\n",
        "\n",
        "# really important to do this before anything else to make experiments reproducible\n",
        "set_seeds()\n",
        "\n",
        "train_dir = 'sample_data/UD_Russian-SynTagRus/ru_syntagrus-ud-train.conllu'\n",
        "val_dir = 'sample_data/UD_Russian-SynTagRus/ru_syntagrus-ud-dev.conllu'\n",
        "test_dir = 'sample_data/UD_Russian-SynTagRus/ru_syntagrus-ud-test.conllu'\n",
        "\n",
        "train, train_words = read_conll(train_dir)\n",
        "val, val_words = read_conll(val_dir)\n",
        "test, test_words = read_conll(test_dir)\n",
        "all_words = train_words + val_words + test_words\n",
        "all_words = set(all_words)"
      ],
      "metadata": {
        "id": "5J4o7_QiH6JH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertModel\n",
        "def get_embed(tokenizer, model, word):\n",
        "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_states = outputs.last_hidden_state[0][0]\n",
        "    return last_hidden_states.detach().cpu()\n",
        "\n",
        "embeds = {}\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "logging.debug('Creating embeddings')\n",
        "ts = time.time()\n",
        "for word in all_words:\n",
        "    embeds[word] = get_embed(tokenizer, model, word)\n",
        "logging.debug(f'{len(embeds)} embeddings were created')\n",
        "te = time.time()\n",
        "logging.info(f'Time of embedding creation: {te-ts:.2g}s')"
      ],
      "metadata": {
        "id": "0fDj1MJpJBV3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4dk0TJSIASC",
        "outputId": "26ad5ed1-6f07-414f-c1b9-95fc39d83633"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Path('/content/app.log').read_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IbKLEjhM2L9",
        "outputId": "acf2ad72-834e-4b56-b222-dec63fc82251"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root - WARNING - This will get logged to a file\n",
            "root - WARNING - New warning\n",
            "root - DEBUG - New debug\n",
            "root - INFO - New info\n",
            "root - DEBUG - Using default Python seed\n",
            "root - INFO - Reading sample_data/UD_Russian-SynTagRus/ru_syntagrus-ud-train.conllu\n",
            "root - DEBUG - 5 sentences read\n",
            "root - INFO - Time: 0.00065s\n",
            "root - INFO - Reading sample_data/UD_Russian-SynTagRus/ru_syntagrus-ud-dev.conllu\n",
            "root - DEBUG - 25 sentences read\n",
            "root - INFO - Time: 0.011s\n",
            "root - INFO - Reading sample_data/UD_Russian-SynTagRus/ru_syntagrus-ud-test.conllu\n",
            "root - DEBUG - 27 sentences read\n",
            "root - INFO - Time: 0.0065s\n",
            "root - DEBUG - Creating embeddings\n",
            "root - DEBUG - 516 embeddings were created\n",
            "root - INFO - Time of embedding creation: 59s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run(train, val, test, options)"
      ],
      "metadata": {
        "id": "oNypIrvK-8yt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "738a5be6-aa12-465b-80e2-b35a78f3e2d8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/5 [00:00<?, ?sentences/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Sentence № 1 # text = Молодая женщина в кокетливой шляпке прошла в кабинет.\n",
            "stack:\n",
            "buffer:Молодая 1 женщина 2 в 3 кокетливой 4 шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:Молодая 1\n",
            "buffer:женщина 2 в 3 кокетливой 4 шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:Молодая 1 женщина 2\n",
            "buffer:в 3 кокетливой 4 шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:Молодая 1\n",
            "buffer:в 3 кокетливой 4 шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:Молодая 1 в 3\n",
            "buffer:кокетливой 4 шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:Молодая 1\n",
            "buffer:кокетливой 4 шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:Молодая 1 кокетливой 4\n",
            "buffer:шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:Молодая 1\n",
            "buffer:шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:\n",
            "buffer:шляпке 5 прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:шляпке 5\n",
            "buffer:прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:\n",
            "buffer:прошла 6 в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:прошла 6\n",
            "buffer:в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:\n",
            "buffer:в 7 кабинет 8 . 9 *root* 0\n",
            "\n",
            "stack:в 7\n",
            "buffer:кабинет 8 . 9 *root* 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-567caec5e613>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-c5f22cb44c18>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(traindata, valdata, testdata, options)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Starting epoch {epoch} (training)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Finished epoch {epoch} (training)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-26edbecd702c>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, trainData, options, irels)\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m#footnote 8 in Eli's original paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-26edbecd702c>\u001b[0m in \u001b[0;36mtrain_sentence\u001b[0;34m(self, sentence, info, irels)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mninf\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#to ensure that we have at least one wrong operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-26edbecd702c>\u001b[0m in \u001b[0;36m__evaluate\u001b[0;34m(self, config, train, irels)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlabeled_GNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-358511fc8c41>\u001b[0m in \u001b[0;36mconfig_to_graph\u001b[0;34m(sentence, stack, buffer)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconfig_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mword_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed_for_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-358511fc8c41>\u001b[0m in \u001b[0;36mget_embed_for_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mword_embeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mword_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-2d426c53aa20>\u001b[0m in \u001b[0;36mget_embed\u001b[0;34m(tokenizer, model, word)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         )\n\u001b[0;32m-> 1022\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1023\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 )\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    613\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    498\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 427\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "В sentence последний элемент -\n",
        "\n",
        "{'id': 0,\n",
        " 'form': '*root*',\n",
        " 'char_rep': '*root*',\n",
        " 'norm': '*root*',\n",
        " 'cpos': 'ROOT-CPOS',\n",
        " 'pos': 'ROOT-POS',\n",
        " 'parent_id': -1,\n",
        " 'relation': 'rroot',\n",
        " 'lemma': '*root*',\n",
        " 'feats': '_',\n",
        " 'deps': '_',\n",
        " 'misc': '_',\n",
        " 'pred_parent_id': None,\n",
        " 'pred_relation': None,\n",
        " 'treebank_id': None,\n",
        " 'proxy_tbank': None,\n",
        " 'pred_pos': None,\n",
        " 'pred_cpos': None,\n",
        " 'projective_order': 0,\n",
        " 'rdeps': [8],\n",
        " 'children': [],\n",
        " 'scores': None,\n",
        " 'parent': None,\n",
        " 'vecs': None}\n"
      ],
      "metadata": {
        "id": "q0jIrXhiBLRM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rQP0uM7BQiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}